{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = \"C:/Users/Administrator/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "driver.get(\"https://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = \"Python爬蟲\"\n",
    "search_bar = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/form/div[2]/div[1]/div[1]/div/div[2]/input\")\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div[3]/form/div[2]/div[1]/div[2]/div[2]/div[2]/center/input[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(keywords)   # 輸入搜尋關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar.send_keys(Keys.ENTER)  # 按下Enter鍵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def google_crawler():\n",
    "    for i in range (1,11):\n",
    "        try:\n",
    "            title = driver.find_element_by_xpath(\"/html/body/div[6]/div[2]/div[9]/div[1]/div[2]/div/div[2]/div[2]/div/div/div[%d]/div/div[1]/a/h3\" %(i))\n",
    "            description = driver.find_element_by_xpath(\"/html/body/div[6]/div[2]/div[9]/div[1]/div[2]/div/div[2]/div[2]/div/div/div[%d]/div/div[2]/div/span\" %(i))\n",
    "            print(\"第\",i,\"筆結果\")\n",
    "            print(\"標題：\",title.text)\n",
    "            print(\"摘要：\",description.text)\n",
    "            print(\"=\"*125)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    total_page = 5             #爬取的總頁數(包含第1頁)\n",
    "    for j in range (1, total_page+1):   \n",
    "        if j < 2:\n",
    "            print(\"第\",j,\"頁\")\n",
    "        elif j == 2:\n",
    "            print(\"第2頁\")\n",
    "        elif j > 2:\n",
    "            print(\"第\",j,\"頁\")\n",
    "        google_crawler()\n",
    "        next_page_button = driver.find_element_by_xpath(\"/html/body/div[6]/div[2]/div[9]/div[1]/div[2]/div/div[5]/div[2]/span[1]/div/table/tbody/tr/td[12]/a/span[2]\").click() #下一頁\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 頁\n",
      "第 1 筆結果\n",
      "標題： [Python教學]Request和BeautifulSoup爬蟲教學，初學者也可以 ...\n",
      "摘要： 2020年2月4日 - 再學會爬蟲前，要先了解HTML架構這次實作會使用到H1、class等元素. 這次實作對象為結婚吧. python中有需多套件針對這次爬蟲，需要有以下四種 ...\n",
      "=============================================================================================================================\n",
      "第 3 筆結果\n",
      "標題： Day-1 Python爬蟲小人生(1) - iT 邦幫忙::一起幫忙解決難題 ...\n",
      "摘要： ... 就需要網路爬蟲來幫我們完成，這隻程式可以幫我們把網站資料爬(下載)下來，不管是圖片還是文字資料，這就是爬蟲，而我們這邊選擇以Python來撰寫，因為Python ...\n",
      "=============================================================================================================================\n",
      "第 4 筆結果\n",
      "標題： 輕鬆學會網路爬蟲，教你用Python爬蟲爬大樂透| 科技的旅程\n",
      "摘要： 2018年5月25日 - AI的領域之中，如何獲取資料並儲存是重要的第一步，網路爬蟲可以是獲取網路資料的重要技能之一。而Python 則是用來做網路爬蟲非常好的工具， ...\n",
      "=============================================================================================================================\n",
      "第 5 筆結果\n",
      "標題： Python爬蟲新手筆記- Pala.tw\n",
      "摘要： Python爬蟲新手筆記. by 吳致賢(Pala); October 1, 2016. 提供給新手的參考筆記，流程說明與參考程式碼，練習範例取得成就感。\n",
      "=============================================================================================================================\n",
      "第 6 筆結果\n",
      "標題： 附範例與完整程式碼！手把手帶著你用Python 做出爬蟲、抓取 ...\n",
      "摘要： 2017年8月4日 - 【我們為什麼挑選這篇文章】爬蟲應用大概是Python 最擅長，也是最初階的練習功能之一了。透過本文深入淺出的，帶有解說的程式碼，能夠讓你用最 ...\n",
      "=============================================================================================================================\n",
      "第 7 筆結果\n",
      "標題： [Python爬蟲教學]7個Python使用BeautifulSoup開發網頁爬蟲的 ...\n",
      "摘要： 2020年2月28日 - 一、BeautifulSoup安裝. BeautifulSoup是一個用來解析HTML結構的Python套件(Package)，將 ...\n",
      "=============================================================================================================================\n",
      "第 8 筆結果\n",
      "標題： Python 使用Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲 ...\n",
      "摘要： 2018年2月1日 - 在這個範例中，我們打算開發一個爬蟲程式，可從Yahoo 的首頁把頭條新聞的標題與網址抓下來，在開發程式之前，我們通常都會先用瀏覽器的開發 ...\n",
      "=============================================================================================================================\n",
      "第 9 筆結果\n",
      "標題： Python爬蟲 - 國立臺北科技大學進修部推廣教育中心\n",
      "摘要： 課程名稱：Python爬蟲. 課程日期：109年10月18日至109年11月08日止. (10/18、10/25、11/1、11/8). 課程時段：週日上午09:00-16:00. 課程時數：24小時. 課程地點：北 ...\n",
      "=============================================================================================================================\n",
      "第 10 筆結果\n",
      "標題： Python-爬蟲初體驗(內有福利） | 程式前沿\n",
      "摘要： 2018年7月27日 - import requests #跟java的導包差不多，python叫匯入庫 res = requests.get('http://news.sina.com.cn/china/')#爬取網頁內容 res.encoding = 'utf-8' ...\n",
      "=============================================================================================================================\n",
      "第2頁\n",
      "第 1 筆結果\n",
      "標題： Python 網路爬蟲Web Crawler 基本教學By 彭彭- YouTube\n",
      "摘要： 喜歡彭彭的教學影片嗎？點擊「加入」按紐取得更多會員服務哦。 加入會員：https://www.youtube.com/channel/UCguZS ...\n",
      "=============================================================================================================================\n",
      "第 2 筆結果\n",
      "標題： Python 爬蟲開發與項目實戰| 天瓏網路書店\n",
      "摘要： 書名：Python 爬蟲開發與項目實戰，ISBN：7111563875，作者：範傳輝，出版社：機械工業出版社，出版日期：2017-06-01，分類：網路爬蟲Web-crawler、程式 ...\n",
      "=============================================================================================================================\n",
      "第 3 筆結果\n",
      "標題： 網路爬蟲(Crawler) - InfoMiner 即時輿情分析平台\n",
      "摘要： 星期三15 四月2015. 開始使用Python 撰寫網路爬蟲( Crawler )，首先必須安裝用Python 的套件管理工具pip 安裝兩個套件： 1. Requests 網路資源(URLs)擷取套件2.\n",
      "=============================================================================================================================\n",
      "第 4 筆結果\n",
      "標題： [系列活動] Python爬蟲實戰 - SlideShare\n",
      "摘要： 2017年8月9日 - 運用requests 發送GET, POST 請求 運用BeautifulSoup 解析HTML 網頁 運用regular expression 尋找目標資訊 運用pandas 將抓到的資訊 ...\n",
      "=============================================================================================================================\n",
      "第 5 筆結果\n",
      "標題： Python 網頁爬蟲入門實戰- 線上教學課程- Hahow 好學校\n",
      "摘要： Python 網頁爬蟲課程，適合已經有Python基礎，卻不知從何練習起的學生。課程將會說明如何撰寫 ...\n",
      "=============================================================================================================================\n",
      "第 6 筆結果\n",
      "標題： Python -網路爬蟲 - 中央研究院生命科學圖書館\n",
      "摘要： ‧網路爬蟲,英文稱做Web Crawler 或Web Scraping,是一個可以從網路獲取資料的技術,也可以說. 是一種按照一定的規則,自動的抓取網路資訊的程式或者腳本。 它可從 ...\n",
      "=============================================================================================================================\n",
      "第 7 筆結果\n",
      "標題： 博客來-Python網路爬蟲：大數據擷取、清洗、儲存與分析：王者歸來\n",
      "摘要： 書名：Python網路爬蟲：大數據擷取、清洗、儲存與分析：王者歸來，語言：繁體中文，ISBN：9789865501020，頁數：560，出版社：深智數位，作者：洪錦魁，出版 ...\n",
      "=============================================================================================================================\n",
      "第 8 筆結果\n",
      "標題： Python爬蟲程式工讀生, 學校實習可｜帕奇巨科技有限公司 ...\n",
      "摘要： 2020年5月11日 - 【工作內容】新竹縣竹北市- - 須會Python, 並曾經在網路爬取資料- 抓取資料及分析資料(BeautifulSoup/…。薪資：時薪160~200元。職務類別：Internet ...\n",
      "=============================================================================================================================\n",
      "第 9 筆結果\n",
      "標題： Python爬蟲：如何高效率入門爬蟲，我們來看看大牛們的學習 ...\n",
      "摘要： 2018年9月13日 - 雪球網：抓取雪球高回報用戶的行為，對股票市場進行分析和預測。 爬蟲是入門Python最好的方式，沒有之一。Python有很多應用的方向，比如後台開發 ...\n",
      "=============================================================================================================================\n",
      "第 10 筆結果\n",
      "標題： 給初學者的Python 網頁爬蟲與資料分析(3) 解構並擷取網頁資料\n",
      "摘要： 2016年12月22日 - <html> <head> <title>我是網頁標題</title> <style> .large { color:blue; text-align: center; } </style> </head> <body> <h1 class=\"large\">我是變色且 ...\n",
      "=============================================================================================================================\n",
      "第 3 頁\n",
      "第 1 筆結果\n",
      "標題： 給初學者的Python 網頁爬蟲與資料分析(3) 解構並擷取網頁資料\n",
      "摘要： 2016年12月22日 - <html> <head> <title>我是網頁標題</title> <style> .large { color:blue; text-align: center; } </style> </head> <body> <h1 class=\"large\">我是變色且 ...\n",
      "=============================================================================================================================\n",
      "第 2 筆結果\n",
      "標題： python網路爬蟲簡介\n",
      "摘要： 2019年1月21日 - 網頁抓取web scraper. 又稱為web harvesting, web data extraction，和網頁爬蟲極為相似，通常指針對獲取特定網域底下的數 ...\n",
      "=============================================================================================================================\n",
      "第 3 筆結果\n",
      "標題： Python 爬虫介绍| 菜鸟教程\n",
      "摘要： Python 爬虫架构主要由五个部分组成，分别是调度器、URL管理器、网页下载器、网页解析器、应用程序（爬取的有价值数据）。 调度器：相当于一台电脑的CPU，主要负责 ...\n",
      "=============================================================================================================================\n",
      "第 4 筆結果\n",
      "標題： Python 爬蟲練習紀錄(五) @ IvanKao的部落格:: 痞客邦::\n",
      "摘要： 2019年9月8日 - 這次共有8個函式: 1.主程式與主程式選單:menu(). 2.分類選單:showall(). 3.使用者輸入要爬蟲的頁數與分類:howmanypages(). 4.分類選擇: ...\n",
      "=============================================================================================================================\n",
      "第 5 筆結果\n",
      "標題： Python 爬蟲實戰課程- 台灣資料科學協會\n",
      "摘要： 在這資料科學蔚為風行的時代，網路爬蟲的技術是一項非常實用的技能，若您有朝思暮想的資料在網路上(例如表特版上被推爆的文章)，卻苦無方法可以爬取；又或是想抓 ...\n",
      "=============================================================================================================================\n",
      "第 6 筆結果\n",
      "標題： 第二屆Python網路爬蟲實戰研習馬拉松業界專家陪你升級打怪 ...\n",
      "摘要： 透過大量的程式實作，逐步地幫學員培養即戰力，我們同時邀集了網路爬蟲領域的資料科學家為您解答學習過程中的各種疑難雜症，紮實的學習內容讓您每天只要花一點 ...\n",
      "=============================================================================================================================\n",
      "第 7 筆結果\n",
      "標題： 分享您的爬蟲專業作品| CakeResume 作品集\n",
      "摘要： 分享您的爬蟲作品。 ... 繼股票資訊爬蟲作品，將資料圖形化茫茫股海中找出符合... January 19, 2020. 89. 6 ... 用python爬蟲結合氣象資料開放平台API串接，使用.\n",
      "=============================================================================================================================\n",
      "第 8 筆結果\n",
      "標題： 使用Python 抓取Google 新聞| 阿布造飛機- 點部落\n",
      "摘要： 2019年4月2日 - 本文介紹如何寫一段python 的程式碼來爬取Google 新聞來使用。 最近有需求要做一隻Python 爬蟲來抓取新聞，與其到各大網路新聞去抓，乾脆直接 ...\n",
      "=============================================================================================================================\n",
      "第 9 筆結果\n",
      "標題： 【Python 爬蟲教學】1個範例，使用Selenium，搞懂抓取圖片文字 ...\n",
      "摘要： 2020年3月13日 - 想透過Python 爬蟲Selenium 抓取圖片？文字資料？不知道怎麼上手嗎？總覺得重複的事情很麻煩，想要簡單一點一鍵搞定嗎？那你看這篇準沒錯 ...\n",
      "=============================================================================================================================\n",
      "第 10 筆結果\n",
      "標題： Python 爬蟲- 圖文課程2 之Urllib - HiSKIO 跨領域學程式| 專業 ...\n",
      "摘要： 這些都是一步步的實作! 之後將會介紹爬蟲的之武器~Requests、Beautiful Soup、Xpath語法與lxml庫的用法、PhantomJS、Selenium、PyQuery!\n",
      "=============================================================================================================================\n",
      "第 4 頁\n",
      "第 1 筆結果\n",
      "標題： 不會Python爬蟲？ - 尋夢園\n",
      "摘要： Python學習資料或者需要代碼、視頻加Python學習群：960410445. 一、爬蟲是什麼？ 如果我們把互聯網比作一張大的蜘蛛網，數據便是存放於蜘蛛網的各個節點，而 ...\n",
      "=============================================================================================================================\n",
      "第 2 筆結果\n",
      "標題： Python爬蟲入門這一篇就夠了- IT閱讀 - ITREAD01.COM\n",
      "摘要： 2019年2月9日 - 爬蟲三要素抓取分析儲存基礎的抓取操作1、urllib 在P... 何謂爬蟲. 所謂爬蟲，就是按照一定的規則，自動的從網路中抓取資訊的程式或者指令碼 ...\n",
      "=============================================================================================================================\n",
      "第 3 筆結果\n",
      "標題： python 网络爬虫与信息采取之异常处理_python_鞋靠人生的 ...\n",
      "摘要： 2017年8月12日 - 本篇文章转自Ryan Mitchell 写的python：网络数据采集网络是十分复杂的。网页数据格式不友好，网站服务器宕机，目标数据的标签找不到，都是很 ...\n",
      "=============================================================================================================================\n",
      "第 4 筆結果\n",
      "標題： 如何讓Python爬蟲一天抓取100萬張網頁| IT人\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摘要： 2019年5月9日 - 本篇只關注如何讓爬蟲的抓取效能最大化上，沒有使用scrapy等爬蟲框架，就是多執行緒+Python requests庫搞定。 對一個網站定向抓取幾十萬張頁面 ...\n",
      "=============================================================================================================================\n",
      "第 5 筆結果\n",
      "標題： Python3網絡爬蟲(三): 偽裝瀏覽器- Python教學 - 極客書\n",
      "摘要： 上一次我自學爬蟲的時候, 寫了一個簡陋的勉強能運行的爬蟲alpha. alpha版有很多問題. 比如一個網站上不了, 爬蟲卻一直在等待連接返回response, 不知道超時跳過; ...\n",
      "=============================================================================================================================\n",
      "第 6 筆結果\n",
      "標題： Python 網路爬蟲與資料視覺化應用實務 - 旗標\n",
      "摘要： 本書實際教您使用Python 的Beautiful Soup、Pandas、Selenium 及Scrapy 來建立爬蟲程式，並依不同的網頁型態使用對應的工具來抓取資料。在取得和儲存資料後，教 ...\n",
      "=============================================================================================================================\n",
      "第 7 筆結果\n",
      "標題： 數據乃AI之基石：用Python爬蟲抓取大量資料|二手書交易資訊 ...\n",
      "摘要： 數據乃AI之基石：用Python爬蟲抓取大量資料. 1二手徵求. 零一、韓要賓、黃園園. 深石數位科技股份有限公司. 9789865003036. 《本書特色》通過實戰教導初學者爬蟲 ...\n",
      "=============================================================================================================================\n",
      "第 8 筆結果\n",
      "標題： Python基礎課程和網路爬蟲入門實戰| Udemy\n",
      "摘要： 這是一堂適合Python程式語言初學者的課程，課程主要是教同學從完全不會寫程式，到能夠撰寫出抓取網路資料的爬蟲程式，課程中示範抓取PTT文章和台鐵時刻表的 ...\n",
      "=============================================================================================================================\n",
      "第 9 筆結果\n",
      "標題： Python爬蟲-抓取GoogleSearch底下的關鍵字廣告- KDZONE\n",
      "摘要： 文章斷點 [基本上這是我這次需要使用到的功能，相關延伸可以參考文章開始的官方文件會有延伸] A.抓取頁面 #!/usr/bin/python #-*-coding:utf-8 -*- import requests ...\n",
      "=============================================================================================================================\n",
      "第 10 筆結果\n",
      "標題： Python 爬蟲的工具列表附Github代碼下載鏈接\n",
      "摘要： 2015年11月11日 - 摘要： 這個列表包含與網頁抓取和數據處理的Python庫(1) 網路(2) 網路爬蟲... 這個列表包含與網頁抓取和數據處理的Python庫. 網路. 通用.\n",
      "=============================================================================================================================\n",
      "第 5 頁\n",
      "第 1 筆結果\n",
      "標題： 05 Python 爬蟲教學| Max行銷誌\n",
      "摘要： 以下程式碼範例是來自於Python 之父Guido van Rossum 和A. Jesse Jiryu Davis 所一起撰寫的web crawler ，主要是展示如何使用asyncio module + aiohttp 來寫網頁 ...\n",
      "=============================================================================================================================\n",
      "第 2 筆結果\n",
      "標題： Python爬蟲|你真的會寫爬蟲嗎？-知識星球\n",
      "摘要： 2019年4月22日 - 爬蟲調度器，主要是配合呼叫其他四個模塊，所謂調度就是取呼叫其他的模板. URL管理器，就是負責管理URL鏈接的，URL鏈接分為已經爬取的和未爬 ...\n",
      "=============================================================================================================================\n",
      "第 3 筆結果\n",
      "標題： wistbean/learn_python3_spider: python爬虫教程系列 ... - GitHub\n",
      "摘要： python爬虫教程系列、从0到1学习python爬虫，包括浏览器抓包，手机APP抓包，如fiddler、mitmproxy，各种爬虫涉及的模块的使用， ...\n",
      "=============================================================================================================================\n",
      "第 4 筆結果\n",
      "標題： [python] 爬蟲實戰筆記- SWC的Data Science之旅\n",
      "摘要： 2019年11月9日 - 點閱: 302. python 爬蟲實戰筆記. 紀錄一下從youtube 學到的爬蟲技巧。目標是把ptt 電影版第一頁的文章爬下來. 單純的抓取靜態網頁. 方法1.\n",
      "=============================================================================================================================\n",
      "第 5 筆結果\n",
      "標題： Python 爬蟲應用— 以台糖易購網為例 - 台糖公司\n",
      "摘要： 2020年5月6日 - 資訊補給站-Python 爬蟲應用— 以台糖易購網為例. 資訊處王柏宗. 網際網路的蓬勃發展，越來越多民眾在網路上尋找資料，卻也因為資訊爆炸，造成 ...\n",
      "=============================================================================================================================\n",
      "第 6 筆結果\n",
      "標題： Python新手教學(1)用爬蟲爬全球股價! | FinLab 量化實驗室\n",
      "摘要： 2019年2月3日 - 此方法可以爬全球股市！今天讓我們回到原點，從最簡單的程式開始教起，想要做股票數據分析，一定要先得到股票資料，所以我們就從股票資料 ...\n",
      "=============================================================================================================================\n",
      "第 7 筆結果\n",
      "標題： 程序員如何煉成Python 爬蟲“王者”？ - 鏈聞ChainNews\n",
      "摘要： 2019年9月27日 - 作者| 周蘿蔔責編| 郭芮出品| CSDN （ID：CSDNnews）本文章精選了五個爬蟲實例，希望能夠給想要入門Python 爬蟲的小夥伴兒們一些幫助。\n",
      "=============================================================================================================================\n",
      "第 8 筆結果\n",
      "標題： Python 網路爬蟲實戰研習馬拉松\n",
      "摘要： 本課程從網路爬蟲的基礎知識談起，包括靜態網頁爬蟲技術、動能網頁爬蟲技術、網站爬蟲框架、各種進階爬蟲技術等實用技術完整涵蓋。透過大量的程式實作，逐步地 ...\n",
      "=============================================================================================================================\n",
      "第 9 筆結果\n",
      "標題： [心得] Python爬蟲入門@ 胖虎的祕密基地:: 痞客邦::\n",
      "摘要： 2020年1月6日 - 2017年首發開始學Python爬蟲(Crawler) 系統環境: windows 7 python3.52 pip 套件列表requests、beautifulsoup4、jupyt.\n",
      "=============================================================================================================================\n",
      "第 10 筆結果\n",
      "標題： Python爬虫入门教程：超级简单的Python爬虫教程 - C语言中文网\n",
      "摘要： 这篇Python 爬虫教程主要讲解以下5 部分内容：. 了解网页；; 使用requests 库抓取网站数据；; 使用Beautiful Soup 解析网页；; 清洗和组织数据；; 爬虫攻防 ...\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
